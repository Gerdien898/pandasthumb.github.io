<!DOCTYPE HTML>
<html lang="en-US">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>The Panda&#8217;s Thumb</title>
  
  <meta property="og:site_name" content="The Panda's Thumb" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="The Panda&#8217;s Thumb" />
  <meta property="og:url" content="https://pandasthumb.org/" />
  <meta property="og:image" content="https://pandasthumb.org/media/roar.jpg" />


  <link rel="stylesheet" type='text/css' href="/css/normalize.css" />
  <link rel="stylesheet" type='text/css' href="//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700,400italic,700italic|Source+Code+Pro:400,700" />
  <link rel="stylesheet" type='text/css' href="/css/gridism.css" />
  <link rel="stylesheet" type='text/css' href="/css/style.css" />
  <link rel="stylesheet" type='text/css' href="/css/github.css" />
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <script type="text/javascript" src="//code.jquery.com/jquery-3.1.1.min.js"></script>
  <script type="text/javascript" src="https://use.fontawesome.com/e6a24c6dde.js"></script>
  <script type="text/javascript" async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>  
  <script src="/js/local.js"></script>

</head>


<body class="wrap">
  <div class="grid page-fill"><div></div></div>
<header class="topbar">
  <div class="grid no-gutters">
    <div class="banner unit whole">
		  <img src="/media/banner.jpg" alt="The Panda's Thumb" />
    </div>
    <nav class="main-nav unit whole align-center">
      <ul>
<li><a href="/" title="Main Page"><i class="fa fa-home" aria-hidden="true"></i>&nbsp;Main</a></li>
<li><a href="/archives/index.html" title="Archives"><i class="fa fa-book" aria-hidden="true"></i>&nbsp;Archives</a></li>
<li><a href="/search.html" title="Searching Panda's Thumb"><i class="fa fa-book" aria-hidden="true"></i>&nbsp;Search</a></li>
</ul>

    </nav>
  </div>
</header>


  <section class="main">

  <div class="grid item">
    <div class="unit whole">
      <article class="blogpost">
        <header>
          <h1><a href="/archives/2022/11/erkell8.html">Science, hypotheses, and intelligent design</a></h1>
          <div class="byline"><i class="fa fa-user-circle" aria-hidden="true"></i> By Lars Johan Erkell</div>
          <div class="attrline"><i class="fa fa-clock-o" aria-hidden="true"></i>
          <span><time pubdate="pubdate" datetime="2022-11-16T13:15:00-07:00">November 16, 2022 13:15 MST</time></span>
          <span><i class="fa fa-comments" aria-hidden="true"></i> <a href="/archives/2022/11/erkell8.html#disqus_thread" data-disqus-identifier="/archives/2022/11/erkell8" class="disqus-comment-count">0 Comments</a></span>
          </div>
        </header>
        <p>&nbsp;</p>
<p><em>This is an additional post by Lars Johan Erkell made on September 8, 2021 in Swedish at the Biolog(g) site after the seven posts 
of his “Breakthrough for Intelligent Design?” series were made.  He has requested that we post it here after 
the second post in that series, to explain his position in that post on what can be considered legitimate 
science.</em></p>

<p>&nbsp;</p>

<p>A central point in the discussion I have with Ola Hössjer in the posts entitled "Breakthrough for
intelligent design?" concerns the limits for what can be considered legitimate science. Since my
responses to his comments on this matter are too long for the comments section, I have made a
separate post on the subject.</p>

<p>The central question is how to formulate a hypothesis, that is, a suggested explanation for a
phenomenon. Hypotheses are not formulated in an arbitrary way; you don't just grab something out
of the air. A hypothesis should be based on prior knowledge. It should also be falsifiable, which
means that it must be possible to show that it is incorrect. The scientific work then consists of testing
the hypothesis. Whether it proves to be true or false, something new has been learned. The
important thing here is that the hypothesis is formulated in such a way that it can be tested in
practice with a clear-cut result. If you cannot do that, you cannot learn anything new. And if you
cannot test your hypotheses, you cannot root your theories in the real world.</p>

<p>However, just because a hypothesis is falsifiable does not mean that it is scientific. For example, "the
Moon is a cheese" is a falsifiable (and falsified) hypothesis. But pure nonsense. If we want to give it a
scientific touch, we can formulate it as a classical syllogism:</p>

<p>Premise 1: The Moon is yellow, round and has craters</p>

<p>Premise 2: A cut cheese is yellow, round and has pits that look like craters</p>

<p>Conclusion: The Moon is a cheese</p>

<p>This conclusion is not just grabbed out of thin air; it is based on an analogy. But it is still nonsense.
My point here is that just because a hypothesis is falsifiable, or is expressed in a formally correct
manner, that does not mean it is plausible or even makes sense.</p>

<p>As an example of a falsifiable hypothesis that is scientifically acceptable, let us take a classic: Darwin's
hypothesis of the common descent of life forms. It implies, among other implications, that older
forms must lie below younger forms in the fossil record. In other words, a fossil of a reliably
identified and reliably dated rabbit (or any other modern mammal) may not be found in Cambrian
deposits, i.e. from a time long before the first mammals emerged. Despite millions of fossils being
unearthed, nothing has yet been found to disprove Darwin's hypothesis. Still, in principle it could
happen, and that would be a fundamental blow to the theory of evolution.</p>

<div align="center">***</div>

<p>One can hear ID proponents argue that ID can also make falsifiable hypotheses. Stephen Meyer
devotes an entire appendix to discussing the matter in his 2009 book <em>Signature in the Cell</em>. He writes
on page 482: "… the theory of intelligent design makes predictions about the kind of features we are
likely to find in living systems if they were in fact intelligently designed". What is important here is
the wording "we are likely to find" - ID's predictions are thus based on what one might vaguely
expect to find. Not on what one <em>must</em> find or on what one <em>must not</em> find, i.e. not on any compelling
predictions.</p>

<p>This means that one cannot clearly falsify an ID hypothesis. As an example, let us take an ID-inspired
hypothesis that Meyer puts forward: "The functional sequences of amino acids within amino 
acid-sequence space should be extremely rare rather than common". He argues that of all possible
combinations of the amino acids that make up proteins, there should be very few combinations that
result in functional protein structures. The first problem is that Meyer does not give a clear limit for
what would be extremely rare and what would not, so the question is impossible to decide in
practice - "extremely rare" can be interpreted in very different ways. The second, and bigger,
problem is that there is no logical connection to a designer - how do we know that the designer
decided that there must be only a few working combinations? We don't. So even if we could confirm
the hypothesis, it would not tell us anything about whether proteins were designed or not.</p>

<p>This ID hypothesis is clearly not about proving ID, but about ruling out an evolutionary explanation. If
it could be shown that there were extremely few working combinations of amino acids, this would be
seen as an argument against the theory of evolution (which, by the way, it is not). In other words,
Meyer tries to demonstrate "non-evolution" and sees this as a sign of design. This is a classic fallacy -
the fact that one explanation does not hold up does not mean that another explanation must be
correct.</p>

<p>Meyer in his appendix has a list of twelve "ID-inspired" predictions of which the above example was
the last one. The other eleven suffer from the same weaknesses. Some of them are pure arguments
against evolutionary processes and have nothing to do with design. Others assume that the designer
is working with a particular type of design which you then want to identify. But you cannot know
what type of design the designer uses, so what you are actually testing is the idea you have about
how the designer should work. Without actual knowledge of the designer, it is impossible to know
how to formulate precise hypotheses. Everything becomes pure conjecture.</p>

<p>As an example of empirical work based on a hypothetical designer, consider a study of the impact of
intercessory prayer on the recovery of patients who have undergone a particular type of heart
surgery.<sup>1</sup> This is a large study with 1800 patients, carried out according to all the rules of the art. The
end result was that no significant effect of prayer was seen. Does this mean that prayer has been
shown not to work? Not at all. The results only show that intercession does not work with the
particular experimental design chosen. Perhaps it would have worked with other patients, other
experimental groups, other control groups, other prayer rituals, other people praying? We don't
know. Since we have no concrete knowledge of the designer, we do not know how the experiment
should be set up to show with certainty the effect of intercessory prayer. We can guess endlessly.
This is not how good hypothesis testing is done - that requires precise, testable hypotheses.</p>

<div align="center">***</div>

<p>Let us leave the hypotheses and move on to what is required of a scientific explanation. Explaining
something means clearly demonstrating the causes of some phenomenon; you connect cause and
effect. You also have to show how the cause leads to the observed phenomenon. A good
explanation, then, involves linking a phenomenon to a known cause through a known mechanism.
Darwin's theory of evolution is a good example. His idea of common descent was quickly accepted by
his contemporaries; it was so obvious that it explained the patterns of nature well. But with natural
selection it was not so. Darwin could not explain the mechanisms of heredity, which was a
prerequisite for understanding natural selection. That is why not many people fully accepted his
theory. However, by the turn of the 20th century, the mechanisms of genetics were starting to be
elucidated, so now the process of evolution was being understood. But it was still not clear exactly
how evolution happened. It wasn't until population genetics had developed sufficiently in the 1930s
and 40s that the theory became widely accepted. By then, the whole chain was clear: known causes
(heredity and variation) caused a known phenomenon (evolution) through a known mechanism
(natural selection).</p>

<p>Today we can understand the entire causal chain. We can understand it at the molecular level as well
as at the population level. We know the molecules and processes that cause evolution. We can
observe and measure them, which allows us to have an evidence-based discussion about the
importance of different factors, and how well different models fit reality. That is how it should be
with a good scientific explanation. It also allows us to formulate and test new hypotheses based on
the knowledge we already have - for example, can cooperation and helpfulness be explained in
evolutionary terms? It turns out that it can. The theory of inclusive fitness provides a robust
evolutionary explanation.</p>

<p>Compare this to an ID explanation of how a complex biological structure would arise. The cause, the
designer, is unknown, and so are the mechanisms by which the design would be implemented. Thus,
we cannot assess how plausible the ID explanation is, or how it compares to other explanations. An
explanation based on unknown causes and unknown mechanisms is, strictly speaking, no explanation
at all - it doesn't make us any wiser. It provides no concrete knowledge. It has no explanatory value.
Nor does it provide a reliable basis for further hypotheses. If you are already firmly convinced that
there is a designer, it may work as a religiously based explanation, but it is scientifically uninteresting.</p>

<p>The fuzziness of ID explanations is characteristic. It is also reflected in the lack of precision in the
concepts used. For example, "complex specified information" is not defined in a way that makes it
measurable or practically useful. Similarly, it is impossible to clearly determine whether a structure is
irreducibly complex or not - distinct criteria are lacking. It is obviously impossible to conduct
meaningful research with such fuzzy concepts. Yet ID proponents refer to these concepts as if they
were clear, meaningful and established. But they are definitely not.</p>

<p>The conclusion is clear: ID cannot provide the kind of mechanistic explanations that are the basis of a
scientific theory. Thus ID cannot compete with established science, and can never be a scientific
alternative. On the other hand, ID could be a complementary explanation on another level: one is
free to imagine a governing intelligence behind all the mysteries of existence, while science provides
the mechanistic explanations of how the world actually works.</p>

<p>Reference:</p>

<p>1) Benson, H., et al: Study of the Therapeutic Effects of Intercessory Prayer (STEP) in cardiac bypass
patients. <em>American Heart Journal</em> (2006) 151, pp. 934-42
https://www.ncbi.nlm.nih.gov/pubmed/16569567</p>

        
      </article>
    </div>
  </div>

  <div class="grid item">
    <div class="unit whole">
      <article class="blogpost">
        <header>
          <h1><a href="/archives/2022/11/erkell2.html">Breakthrough for Intelligent Design? (Part 2)</a></h1>
          <div class="byline"><i class="fa fa-user-circle" aria-hidden="true"></i> By Lars Johan Erkell</div>
          <div class="attrline"><i class="fa fa-clock-o" aria-hidden="true"></i>
          <span><time pubdate="pubdate" datetime="2022-11-16T13:00:00-07:00">November 16, 2022 13:00 MST</time></span>
          <span><i class="fa fa-comments" aria-hidden="true"></i> <a href="/archives/2022/11/erkell2.html#disqus_thread" data-disqus-identifier="/archives/2022/11/erkell2" class="disqus-comment-count">0 Comments</a></span>
          </div>
        </header>
        <figure><img src="/uploads/2022/Biologg_Banner_900.jpg" alt="Biolog(g) banner" />
<figcaption>The text is a pun in Swedish: "Logg" means something like a ship´s log or a logbook. A blog is "blogg". 
So "Biolog(g)" is a biologist´s log or blog.</figcaption>
</figure>

<p>&nbsp;</p>
<p>This is part 2 of a series of 7 posts by Lars Johan Erkell, with comments on each by Ola Hössjer and a reply by Erkell.  An eighth post by Erkell is near this one, put here because he refers to it. Part 1 will be found <a href="https://github.com/PandasThumb/pandasthumb.github.io/edit/source/_posts/2022/2022-11-09-erkell1.md">here</a>._</p>

<h2 id="breakthrough-for-intelligent-design-part-2">Breakthrough for Intelligent design? (Part 2)</h2>
<p>November 13, 2020</p>

<p>by Lars Johan Erkell</p>

<p><strong>How do you calculate design?</strong></p>

<p>What stands out about Thorvaldsen and Hössjer’s work, and what makes me write these blog posts, is that they raise the question of how one could demonstrate fine-tuning and design using scientific methods. In any case, how one could imagine doing so; it doesn’t get more concrete than that.</p>

<p>Thorvaldsen and Hössjer carefully discuss the statistical methods they use, or rather believe that one can use. The main line is – as always with ID – that you try to support ID by primarily criticizing the theory of evolution. But you cannot prove theory A by showing that theory B is bad. The authors are also aware of this. They write in section 6.3:</p>

<blockquote>
  <p>However, one may argue that the most suitable approach of science is to compare the best explanations found so far within two competing worldviews. This naturally leads to model selection. … It is possible for some problems to suggest a design model M1 that competes with the currently most promising naturalistic model M2, in terms of which model explains the data the best.
The authors therefore want to compare an evolutionary model with a design model by using statistical methods to determine which of them is more probable. And it is clear that the intention is to make the comparison based on concrete data. But from which models, and from which data?</p>
</blockquote>

<p>In their critique of evolutionary theory, a number of well-known themes are addressed, primarily “irreducible complexity” on several levels; in individual proteins, in protein complexes and in entire networks. Also the “Cambrian explosion” and the so-called the waiting time problem is addressed. What these have in common is that the authors believe that the structures of life are so complex and thus so improbable that they could never arise naturally. However, this is not a view shared by established science – here the arguments are seen as contrived.</p>

<p>The question now is, in practical terms, these problems could be calculated. A question that has been dealt with extensively - and which is probably the easiest to calculate - concerns the probability that a functioning protein will be able to arise through naturalistic mechanisms. Thorvaldsen and Hössjer mention in section 4.2 two strategies for doing this:</p>

<p>The first is based on the fact that protein consists of one or more chains of amino acids that must be in a certain sequence. Since there are 20 different amino acids to choose from, there are countless combinations. In a small protein consisting of 150 amino acids, the different amino acids can be combined in 10<sup>50</sup> to 10<sup>74</sup> different ways. These are astronomically large numbers; the probability that the “right” combination would occur by chance is vanishingly small. The big problem with this strategy, however, is that no sane biologist believes that proteins form in this random way.</p>

<p>The evolutionary biological view is instead that the first enzymes consisted of short peptide chains with a small number of amino acids – it is known that such chains can have enzymatic activity.<sup>1</sup> That such peptide chains could be formed by chance is not unreasonable. They may not have been as efficient as today’s enzymes, but if they had sufficient enzyme activity, they would have been selected and evolved into larger and more efficient molecules. So no one believes that proteins are formed in the way that Thorvaldsen and Hössjer are suggesting. It is a little strange that they mention this bizarre idea at all. It is completely irrelevant.</p>

<p>The other strategy is to set up a hypothetical evolutionary tree for how a certain protein might have evolved, and then calculate the probability of that process. But there is a lot of knowledge that is missing in order to be able to make credible calculations of this kind, not least because we have to reckon with an evolution that extends over billions of years. We would need detailed knowledge of which organisms are involved, mutation frequencies, population sizes, selection pressure and much else that is impossible to know in retrospect. This is not a realistic path. Nor, as far as I know, has anyone attempted to set up any detailed scenario of this kind.</p>

<p>The conclusion is that it is not practically possible to statistically calculate the probability that a protein could evolve via natural mechanisms. The difficulties are so enormous that it will probably never be possible. And yet this was the simplest of the cases discussed.</p>

<div align="center">***</div>
<p>Thorvaldsen and Hössjer’s strategy for demonstrating fine-tuning is based on a statistical comparison between a naturalistic model M2 and a design model M1. We then need to calculate the probability for both models in order to compare them. We have already seen that it is practically impossible to calculate the probability that a complex biological structure can arise according to a naturalistic model. But how to calculate the likelihood of a design model? It is something the authors wisely do not go into. Here we are in big trouble.</p>

<p>In order to be able to calculate the probability of how a complex biological structure can arise, we must have a credible and detailed model of the process. This also applies if there is a conscious design behind it. We must therefore have knowledge of the designer in order to assess the probability that he/she/it wanted the design exactly the way we see it. This requires detailed knowledge – we need to understand exactly how the designer thinks, what the intentions, plans and means are. In order to make statistical calculations, we must have actual data, numbers.</p>

<p>Design proponents, however, are careful not to say anything about who the designer might be, or what qualities the designer might have. This makes it fundamentally impossible to calculate the statistical probability of a design process. So it’s not just practically impossible, as with the naturalistic model, it’s fundamentally impossible.</p>

<p>The statistical model Thorvaldsen and Hössjer have put forward to demonstrate design is misconceived and unworkable – it is based on the unreasonable assumption that it is possible to make a statistical estimate of the probability that an unknown designer would have acted in a certain way. It is a mystery that they chose to publish it.</p>

<p>Notes:</p>

<ol>
  <li>Short peptides can spontaneously form stable complexes that have enzymatic activity. See: Jason Greenwald et. al.: Peptide Amyloids in the Origin of Life. J Mol Biol (2018) vol. 430, pp. 3735–3750 <a href="https://pubmed.ncbi.nlm.nih.gov/29890117/">here</a></li>
</ol>

<p>&nbsp;</p>

<p><strong>Comment by Ola Hössjer</strong>
June 29, 2021 3:00 a.m</p>

<p><strong>Part 2. About counting on design</strong></p>

<p>In order to be able to estimate the probability that a biological system should have arisen by chance (so step a) in the fine-tuning argument) a naturalistic model M2 is required that describes how development or evolution took place. The fact that the model is naturalistic means that it contains only natural explanatory mechanisms. When it comes to biological evolution, i.e. the development of complicated life forms from simple single-celled organisms, the five naturalistic mechanisms are usually involved i) mutations, ii) genetic drift, i.e. random variation in how reproductive the individuals in a parental generation are, iii) natural selection, iv) recombinations of genetic material from a pair of parents, and v) the mixing of gene pools caused by geographic migration.</p>

<p>Erkell claims that it is practically impossible to give a reasonable estimate of the probability that, for example, a protein could have evolved in accordance with a naturalistic model M2. I agree that this is extremely difficult, since such a model must necessarily be complicated, with more or less unknown parameters. Nevertheless, I believe that there is a feasible way to demonstrate the difficulty of naturalistic processes in producing complex structures. If you only focus on certain properties of the protein that according to M2 must have evolved, you get a conservative upper estimate of the probability that a protein was obtained through evolutionary processes. To also take into account the fact that several of the model’s parameters (such as selection pressure, mutation rate, population sizes, generation times, etc.) can be difficult to estimate from the data with good accuracy, a so-called sensitivity analysis can be used to calculate how the upper estimate of the probability for the development of the protein changes when the constituent parameters change. If this upper estimate of the probability is small for all biologically reasonable values of the included parameters, an argument has been given for the difficulty of the proposed naturalistic model M2 to explain the origin of the given protein. I therefore argue, contrary to Erkell, that the first step a) of our method for detecting fine-tuning is highly feasible in practice.</p>

<p>The second part b) of our fine-tuning argument consists in finding a measure f(x) of how specified a biological system x is. As mentioned in the introduction, f(x) fastens on some characteristic that the observer recognizes, and which in many cases brings to mind that an intelligent designer is behind the origin of the system. In TH2020 we give several examples of how the system x and its specification f(x) can be chosen. An example is that x corresponds to a protein or a molecular machine, and that the specification indicates how many parts must be in place for x to function. Another example is that f(x) indicates the biological fitness of an organism x, i.e. its reproductive capacity. In connection with the latter example, we argue in TH2020 that evolution will eventually break down the genetic material of a species because most mutations are harmful or neutral. The consequence is then that the fitness of individuals of the species decreases over time. This in turn means that the probability in a) becomes very low for an evolutionary model M2, based on the aforementioned mechanisms i)-v), to be able to explain that the organism in question arose during millions of years of development, because the genetic material during such long time has had time to be depleted.</p>

<p>But if a naturalistic model M2 has difficulty explaining the emergence of a biological system that contains some form of specification, the question is whether there is any other better explanatory model. At the end of TH2020, we give examples of design- or creationist-inspired models M1 that we believe have greater possibilities than M2 to explain the emergence of the fine-tuned system. To make such reasoning more rigorous, it is necessary to show that the probability of the emergence of the given system is much higher for the design model M1 than for the naturalistic model M2. In the example above, where f(x) corresponds to the biological fitness of an organism x, we refer to various articles where a design model is described, which in addition to the aforementioned (micro)evolutionary mechanisms i)-v) adds a sixth mechanism vi) in the form of genetic variation in a first created pair, from which all individuals in the species descend. According to such a design model M1, the emergence of species can be explained by a combination of created variation (mechanism vi) and a short-term, small-scale microevolution (mechanisms i-v). The problem of genetic depletion then becomes much less, because the created variation makes it possible to assume that the species arose relatively recently, so that the genetic erosion, caused by the harmful mutations, acted for a much shorter time<sup>2</sup>.</p>

<p>Erkell is strongly critical of us introducing a design model to explain the emergence of a biological system. He writes:</p>

<blockquote>
  <p>In order to be able to calculate the probability of how a complex biological structure can arise, we must therefore have a credible and detailed model of the process. This also applies if there is a conscious design behind it. We must therefore have knowledge of the designer in order to assess the probability that the person concerned wanted his design exactly the way we see it to be. This requires detailed knowledge – we need to understand exactly how the designer thinks, what intentions, plans and means they have. In order to make statistical calculations, we must have concrete data, numbers.</p>

  <p>However, the design movement is very careful not to say anything about who the designer would be, or what qualities the designer would have. This makes it fundamentally impossible to calculate the statistical probability of a design process. It is thus not only practically impossible, as with the naturalistic model, it is fundamentally impossible.</p>
</blockquote>

<p>I completely agree with Erkell that it is difficult to determine exactly what plans or intentions a designer has. But this is also not necessary to know. It is enough to let design-inspired thinking generate concrete falsifiable hypotheses. A design-inspired model can therefore be perfectly combined with the hypothetical-deductive method, which forms the basis of empirical science, according to the following three steps:</p>

<p>1) Propose a falsifiable hypothesis, which can contain both natural mechanisms and design-inspired parts.</p>

<p>2) Evaluate and see if the hypothesis in 1) is consistent with the data.</p>

<p>3) If the agreement in 2) is not good, go back to 1) and propose a better hypothesis.</p>

<p>Erkell makes very far-reaching, not to say unreasonable demands on the design model, because he is not satisfied with falsifiable hypotheses. Instead, he also wants to include characteristics of the designer that can often be difficult to test scientifically. Although it is probably so interesting to have a conversation about what intentions the designers have, this has to do with the interpretation and the reason for the emergence of hypotheses, which is not required for the hypothetico-deductive method. One can thus use more or less intuitive design arguments to formulate testable hypotheses, without having to test the reasoning that led to the formulation of the hypotheses.</p>

<p>Furthermore, Erkell’s reasoning backfires like a boomerang on himself. Shouldn’t he make the same rigorous demands on naturalistic models M2, where the interpretation of them is included? How, for example, should chance in an evolutionary model be explained? Is it epistemic chance (as a way of describing lack of knowledge), ontological chance (genuine non-determinism) or should quantum mechanics be used to explain the emergence of chance? Which interpretation of quantum mechanics should be used in that case? If these questions cannot be given an unequivocal answer, Erkell risks sawing off the secular branch of science he himself has set himself up for.</p>

<p>2) This is usually called Haldane’s dilemma. A historical overview of Fisher’s Fundamental Theorem of Natural selection (which is closely related to Haldane’s Dilemma) is given in Basener W., Cordova S., Hössjer O. and Sanford J. (2021). Dynamical Systems and Fitness Maximization in Evolutionary Biology. In: Sriraman B. (eds) Handbook of the Mathematics of the Arts and Sciences. Running, Cham.</p>

<p>&nbsp;</p>

<p><strong>Reply by Lars Johan Erkell</strong>
September 8, 2021 6:12 am</p>

<p>In this section, we get into the core of the work, your statistical model to detect fine-tuning/design. It assumes that you can calculate the probability that a biological structure can evolve via natural mechanisms, an extremely difficult task. You write that you can make meaningful estimates of the probability of a protein being able to evolve by doing a sensitivity analysis of an upper estimate of this probability. If the variation of this estimate is small for all biologically plausible values of the involved parameters, one would have an argument for the difficulty of the proposed naturalistic model.</p>

<p>But how do you get “all biologically reasonable values”? It is not enough to count on a single gene – genes (and proteins) interact in complex networks, and selection pressure acts on the entire network. The interaction between genes is called epistasis, and it must be included in your model. Ecology is also crucial because the selection pressure is entirely dependent on the organism’s environment. The problem is that there are astronomically many possibilities for epistatic (and ecological) interactions, and you have no clues as to which might be the relevant ones. You cannot count on a certain protein “all else being equal”; because the genome is constantly changing, “all else is not equal”. All of this means that you are nowhere near a realistic model of an evolution that has taken place in countless steps over millions or billions of years.</p>

<p>Apart from all this, there is also a fundamental flaw in the approach, namely that it assumes the probability of a process with a definite goal in the form of a definite structure (at least that’s how ID advocates tend to calculate). But evolutionary processes have no goal. As far as proteins and protein complexes are concerned, there are a huge number of structures that have the same or similar function, and it is one of these that will be selected. It is thus the probability that the function - not the exact structure - will evolve that is important.</p>

<p>In any case, you mean that “our method of detecting fine-tuning is highly feasible”. If so, why haven’t you done so? Why don’t you at least have a discussion of which factors would be included in such a calculation, how they should be identified, how they should be estimated, how they should be weighed against each other, etc.? Then—and only then—would this article be interesting. It would be even more interesting if you could succeed with the second part of your method, namely calculating the probability of design. If you are to test the probability that a certain structure is designed, you must know the characteristics of the designer - design is an act of will, and it is the probability of that act of will that you must calculate. And that is of course impossible without in-depth knowledge of the designer. You don’t write anything about how this would work, and that doesn’t surprise me; I suspect you have no idea. At least I don’t have it. But this is necessary if you want to be able to compare M1 and M2. That comparison is the very core of your method. But you comment on it like this:</p>

<p>“Erkell makes very far-reaching, not to say unreasonable, demands on the design model, because he is not satisfied with falsifiable hypotheses. Instead, he also wants to include characteristics of the designer that can often be difficult to test scientifically.”</p>

<p>There’s no getting away from this: the probability of a design hypothesis includes the probability that a designer really wants to accomplish a certain thing. Without intention no design. If we imagine an omnipotent designer (which you probably do) it is only an act of will; no practical complications exist. But I get curious; you write “characteristics of the designer that can often be difficult to test scientifically”, which must mean that there are actually characteristics of the designer that can be scientifically tested. What are they? How can you test them? Here we get into really central questions about scientific hypotheses. That discussion is so important and extensive that it hardly fits in the comments section. I have therefore written <a href="https://github.com/PandasThumb/pandasthumb.github.io/edit/source/_posts/2022/2022-11-09-erkell8.md">a separate post</a> on the matter, “Science, hypotheses and Intelligent Design”.</p>

<p>In your comment you also touch on completely different things: you talk about “genetic erosion” and refer in a footnote to “Haldane’s dilemma”. Here you are confusing two things. Haldane’s dilemma is not about some kind of erosion 
but about how fast evolution can go, more specifically whether there was enough time for the gene substitutions that must have taken place from the time of the common ancestor of humans and chimpanzees until today. The genetic erosion you talk about is John Sanford’s genetic entropy, a completely different matter. It would consist of a slow and inevitable genetic decay that would lead to our demise. However, neither Sanford nor anyone else has been able to show that this decay actually occur. Sanford builds on an earlier, now dismissed, idea that a genetic “catastrophe” could occur if enough harmful mutations accumulate in a genome. However, it has never been shown that such catastrophes actually take place, but rather that they do not (Springman, R. et al: Evolution at a High Imposed Mutation Rate: Adaptation Obscures the Load in Phage T7. Genetics (2010)184: 221 –232); Summers, J., Litwin, S.: Examining The Theory of Error Catastrophe. J. Virol., (2006) 80, 20–260). So forget about genetic entropy.</p>

<p>In conclusion, you suggest that I should place the same strict demands on my own research as I do on yours. But that’s exactly what I do - I make the same demands on your research that I myself have to live up to. Regarding your question about chance, I (and my colleagues) assume an ontological chance, since chemical reactions are based on the interaction between elementary particles and these are subject to the quantum laws in their Copenhagen interpretation. This is the basis of the molecular orbital theory, and thus of the chemistry and biology, I was once taught.</p>


        
      </article>
    </div>
  </div>

  <div class="grid item">
    <div class="unit whole">
      <article class="blogpost">
        <header>
          <h1><a href="/archives/2022/11/erkell1.html">Breakthrough for Intelligent Design? (Part 1)</a></h1>
          <div class="byline"><i class="fa fa-user-circle" aria-hidden="true"></i> By Lars Johan Erkell (with comments by Ola Hössjer)</div>
          <div class="attrline"><i class="fa fa-clock-o" aria-hidden="true"></i>
          <span><time pubdate="pubdate" datetime="2022-11-09T13:00:00-07:00">November 9, 2022 13:00 MST</time></span>
          <span><i class="fa fa-comments" aria-hidden="true"></i> <a href="/archives/2022/11/erkell1.html#disqus_thread" data-disqus-identifier="/archives/2022/11/erkell1" class="disqus-comment-count">0 Comments</a></span>
          </div>
        </header>
        <figure><div align="center"><img src="/uploads/2022/Biologg_Banner_900.jpg" alt="Biolog(g) banner" /></div>
<div align="center"><figcaption>The text is a pun in Swedish: "Logg" means something like a ship´s log or a logbook.<br /> A blog is "blogg". 
So "Biolog(g)" is a biologist´s log or blog.</figcaption></div></figure>

<p>&nbsp;</p>

<p><em>This exchange consists of seven posts, each with a comment by Ola Hössjer and a reply by Lars Johan Erkell, plus one other post by Erkell.  It 
is a translation, mostly by Google Translate, from <a href="https://biologg.wordpress.com/author/larserkell/">the original 2020 Swedish posts and comments</a>.  Erkell and Hössjer have kindly corrected the translation.  You and they are welcome to comment at Panda’s Thumb.  Keep in mind that the posts and these appended comments were written two years ago and thus cannot take more recent comments here into account. We hope to publish the sections on seven consecutive Wednesdays (we chose the day of the week without remembering its connection to ancient days in Sweden).  Readers and these authors are invited to contribute further comments in our Disqus comment system.</em></p>

<p><em>This week’s post starts with an introduction by Lars Johan Erkell, followed by the first of his posts at Biolog(g) and a comment by Ola Hössjer followed by a rejoinder by Lars Erkell.</em></p>

<p>&nbsp;&nbsp;</p>

<h2 id="introduction">Introduction</h2>

<p>by Lars Johan Erkell</p>

<h3 id="a-breakthrough-for-intelligent-design">A breakthrough for Intelligent Design?</h3>

<p>Two years ago, Steinar Thorvaldsen and Ola Hössjer, professors of Informatics and Mathematical
Statistics, respectively, published <a href="https://www.sciencedirect.com/science/article/pii/S0022519320302071?via%3Dihub"><strong>an article</strong></a> titled “Using statistical methods to model the fine-tuning
of molecular machines and systems” in “Journal of Theoretical Biology” a regular scientific journal.
Within the Intelligent Design (ID) community the publication was seen as a breakthrough for ID as
science. A close reading of the paper, however, is not convincing. In seven blog posts on “Biolog(g)”
(a blog run by the staff at the Institute for biology and environmental science at the University of
Gothenburg, Sweden) I therefore have detailed my critique on four specific points, and also asked
how this paper could be published.</p>


        
        <p class="morelink"><a href="/archives/2022/11/erkell1.html#more">Continue Reading</a> <i class="fa fa-arrow-circle-o-right" aria-hidden="true"></i></p>
        
      </article>
    </div>
  </div>

  <div class="grid item">
    <div class="unit whole">
      <article class="blogpost">
        <header>
          <h1><a href="/archives/2022/11/this-mornings-eclipse.html">This morning&apos;s eclipse of the moon</a></h1>
          <div class="byline"><i class="fa fa-user-circle" aria-hidden="true"></i> By Matt Young</div>
          <div class="attrline"><i class="fa fa-clock-o" aria-hidden="true"></i>
          <span><time pubdate="pubdate" datetime="2022-11-08T10:25:00-07:00">November 8, 2022 10:25 MST</time></span>
          <span><i class="fa fa-comments" aria-hidden="true"></i> <a href="/archives/2022/11/this-mornings-eclipse.html#disqus_thread" data-disqus-identifier="/archives/2022/11/this-mornings-eclipse" class="disqus-comment-count">0 Comments</a></span>
          </div>
        </header>
        <figure>
<img src="/uploads/2022/DSC05373_Lunar_Eclipse_600.jpg" alt="Eclipse photo" />
<figcaption><a href="https://www.timeanddate.com/eclipse/map/2022-november-8">This morning's eclipse of the moon</a> as seen from Boulder, Colorado, at approximately 4 a.m., near maximum.
</figcaption>
</figure>

        
      </article>
    </div>
  </div>

  <div class="grid item">
    <div class="unit whole">
      <article class="blogpost">
        <header>
          <h1><a href="/archives/2022/11/comet-neowise.html">Comet Neowise</a></h1>
          <div class="byline"><i class="fa fa-user-circle" aria-hidden="true"></i> By Matt Young</div>
          <div class="attrline"><i class="fa fa-clock-o" aria-hidden="true"></i>
          <span><time pubdate="pubdate" datetime="2022-11-07T12:00:00-07:00">November 7, 2022 12:00 MST</time></span>
          <span><i class="fa fa-comments" aria-hidden="true"></i> <a href="/archives/2022/11/comet-neowise.html#disqus_thread" data-disqus-identifier="/archives/2022/11/comet-neowise" class="disqus-comment-count">0 Comments</a></span>
          </div>
        </header>
        <p>Photograph by <strong>Bob Gitzen</strong>.</p>

<p>Photography contest, <strong>Honorable Mention</strong>.</p>

<figure>
<img src="/uploads/2022/Gitzen_CometNeowise.jpg" alt="Comet" />
<figcaption><a href="https://en.wikipedia.org/wiki/Comet_NEOWISE">Comet Neowise</a>, 4:40 a.m., 7/10/20, Lime Ridge Trail, Walnut Creek, California.
</figcaption>
</figure>

        
      </article>
    </div>
  </div>

</section>

<script id="dsq-count-scr" src="//the-pandas-thumb.disqus.com/count.js" async></script>



  <footer>
<div class="grid">
<table bgcolor="204517">
<tr><td>&nbsp;&nbsp;&nbsp;&nbsp;</td><td>
  <div align="left">
    <p>&nbsp;&nbsp;To see earlier posts, select the Archives at the top of this page</p>
    <p></p>
  </div>
  <div id="RecentComments" class="dsq-widget">
      <div align="center">
       <h2>Recent Comments</h2>
       <P>
       To see the comment in context of the discussion click on the text that indicates how long ago the comment was posted, such as "2 hours ago".  Then wait for the post 
     and then the comments to load (may take many seconds).  The comment should have a yellow vertical bar next to the commenter avatar.
      <P>
    </div>
    <div>
     <script type="text/javascript" src="https://the-pandas-thumb.disqus.com/recent_comments_widget.js?num_items=99&hide_mods=0&hide_avatars=0&avatar_size=32&excerpt_length=100"></script>
    </div>
  </div>
</td></tr>
  <tr><td></td><td><div class="unit whole">
      <p>Copyright &copy; The Panda&#8217;s Thumb and original authors &mdash; Content provided under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons BY-NC-ND License 4.0</a>.</p>
    <p></p>
    </div>
    </td></tr>
  </table>
  </div>
  </footer>

  

</body>

</html>


